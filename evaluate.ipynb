{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[UNDER CONSTRUCTION]\n",
    "\n",
    "# 'A Novel Hybrid Convolutional Neural Network for Accurate Organ Segmentation in 3D Head and Neck CT Images' - Reproduction Evaluation\n",
    "\n",
    "In this work the A Novel Hybrid Convolutional Neural Network for Accurate Organ Segmentation in 3D Head and Neck CT Images [1] model was reproduced using the PyTorch framework, with some assumptions. Also, as the authors did not explicitly specify the functionality of the Hybrid Dilated Convolution (HDC) module, a novel version of it was implemented, inspired by [1] and [2]. \n",
    "\n",
    "## Assumptions\n",
    "1. The full CT scanned images were cropped around the brainstem to reduce the model resolution from 256x256x96 to 128x128x48.\n",
    "2. In our dataset, compared to the original MICCAI 2015 challenge dataset, voxel corrections have already been made. Our dataset was the courtesy of the TU Delft Deep Learning cours.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. Load the dataset\n",
    "2. Load the model\n",
    "3. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Data loader\n",
    "from torch.utils.data import DataLoader\n",
    "from src.Data.CTDataset import CTDataset\n",
    "from src.Data.DataCreator import DataCreator\n",
    "\n",
    "from src.utils import Logger\n",
    "\n",
    "Logger.initialize(log_path=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, data downloaded to 'download_data'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://github.com/prerakmody/hansegmentation-uncertainty-qa/releases/download/v1.0/test_offsite.zip\"\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "file_name = url.split('/')[-1]\n",
    "dir_path = Path(\".\") / Path(\"download_data\")\n",
    "path = dir_path / file_name\n",
    "if not os.path.isdir(dir_path):\n",
    "    print(\"Creating directory {}\".format(dir_path))\n",
    "    os.mkdir(dir_path)\n",
    "# writing the file to the local file system\n",
    "\n",
    "    with open(path, \"wb\") as f:\n",
    "        print(\"Downloading %s\" % file_name)\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_length = response.headers.get('content-length')\n",
    "\n",
    "        if total_length is None: # no content length header\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            dl = 0\n",
    "            total_length = int(total_length)\n",
    "            chunk_size = int(total_length/100)\n",
    "            for data in response.iter_content(chunk_size=chunk_size):\n",
    "                dl += len(data)\n",
    "                f.write(data)\n",
    "                done = int(50 * dl / total_length)\n",
    "                sys.stdout.write(\"\\r[%s%s][%d %%]\" % ('=' * done, ' ' * (50-done), done * 2) )    \n",
    "                sys.stdout.flush()\n",
    "\n",
    "    print(\"Zip file downloaded. Extracting...\")\n",
    "\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dir_path)\n",
    "    print(\"Files extracted, removing zip file.\")\n",
    "    os.remove(path)\n",
    "print(f\"Done, data downloaded to '{dir_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data object for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG     Creating transformations for sample 0 at download_data/test_offsite/data_3D/0522c0708\n",
      "LOG     Creating transformations for sample 3 at download_data/test_offsite/data_3D/0522c0659\n",
      "LOG     Creating transformations for sample 4 at download_data/test_offsite/data_3D/0522c0661\n",
      "LOG     Creating transformations for sample 5 at download_data/test_offsite/data_3D/0522c0667\n",
      "LOG     Creating transformations for sample 6 at download_data/test_offsite/data_3D/0522c0669\n",
      "LOG     Creating transformations for sample 7 at download_data/test_offsite/data_3D/0522c0746\n",
      "LOG     Creating transformations for sample 9 at download_data/test_offsite/data_3D/0522c0598\n",
      "LOG     Creating transformations for sample 10 at download_data/test_offsite/data_3D/0522c0555\n",
      "LOG     Creating transformations for sample 12 at download_data/test_offsite/data_3D/0522c0727\n",
      "LOG     Creating transformations for sample 13 at download_data/test_offsite/data_3D/0522c0576\n",
      "\u001b[94mINFO    Started loading the data set with possibly 79 samples (preloading inactive)\u001b[0m\n",
      "LOG     Attempt to generate a dataset instance\n",
      "\u001b[94mRUN     100.0% .................................................. creating dataset\u001b[0m\u001b[0m\n",
      "\u001b[92mDONE    Loading of data completed\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "            \"root\": Path(\".\") /\"download_data\"/\"test_offsite\" / \"data_3D\",\n",
    "            \"num_workers\": 0,\n",
    "            \"labels\": [\n",
    "                \"BrainStem\",\n",
    "                \"Chiasm\",\n",
    "                \"Mandible\",\n",
    "                \"OpticNerve_L\",\n",
    "                \"OpticNerve_R\",\n",
    "                \"Parotid_L\",\n",
    "                \"Parotid_R\",\n",
    "                \"Submandibular_L\",\n",
    "                \"Submandibular_R\"\n",
    "            ],\n",
    "            \"label_transforms\": [\n",
    "                {\n",
    "                    \"name\": \"Transpose\",\n",
    "                    \"dim_1\": 0,\n",
    "                    \"dim_2\": -1\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"CropAroundBrainStem\",\n",
    "                    \"width\": 270,\n",
    "                    \"height\": 270,\n",
    "                    \"depth\": 48\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"EasyResize\",\n",
    "                    \"width\": 256,\n",
    "                    \"height\": 256,\n",
    "                    \"depth\": 48\n",
    "                }\n",
    "            ],\n",
    "            \"sample_transforms\": [\n",
    "                {\n",
    "                    \"name\": \"Transpose\",\n",
    "                    \"dim_1\": 0,\n",
    "                    \"dim_2\": -1\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"CropAroundBrainStem\",\n",
    "                    \"width\": 270,\n",
    "                    \"height\": 270,\n",
    "                    \"depth\": 48\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"EasyResize\",\n",
    "                    \"width\": 256,\n",
    "                    \"height\": 256,\n",
    "                    \"depth\": 48\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"StandardScaleTensor\"\n",
    "                }\n",
    "            ],\n",
    "            \"output_transforms\": [\n",
    "                {\n",
    "                    \"name\": \"EqualSubCubing\",\n",
    "                    \"split\": 2,\n",
    "                    \"padding\": 6\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "data_output_path = Path(\".\")\n",
    "data_creator = DataCreator(data, base_path = data_output_path)\n",
    "processed_data_path = data_creator.build_dataset()\n",
    "print(processed_data_path)\n",
    "eval_dataset = CTDataset(\n",
    "    processed_data_path,\n",
    "    preload=False,\n",
    "    label_transforms=data[\"label_transforms\"],\n",
    "    sample_transforms=data[\"sample_transforms\"],\n",
    "    output_transforms=data[\"output_transforms\"],\n",
    "    label_structure=data[\"labels\"],\n",
    "    no_logging=False,\n",
    ")\n",
    "eval_data = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
    "print(eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising organNet with [[1, 2, 7, 11, 13], [1, 2, 7, 13, 17], [5, 9, 17]], padding: yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrganNet25D(\n",
       "  (two_d_1): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (layer): Sequential(\n",
       "        (0): Conv3d(1, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=same, dilation=(1, 2, 5))\n",
       "        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBNReLU(\n",
       "      (layer): Sequential(\n",
       "        (0): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=same, dilation=(1, 2, 5))\n",
       "        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (two_d_2): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (layer): Sequential(\n",
       "        (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=same, dilation=(1, 2, 5))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBNReLU(\n",
       "      (layer): Sequential(\n",
       "        (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=same, dilation=(1, 2, 5))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (coarse_3d_1): DoubleConvResSE(\n",
       "    (conv): Sequential(\n",
       "      (0): ConvBnReLU3d(\n",
       "        (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): ConvBnReLU3d(\n",
       "        (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (resse): Sequential(\n",
       "      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Unflatten(dim=1, unflattened_size=(32, 1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (coarse_3d_2): DoubleConvResSE(\n",
       "    (conv): Sequential(\n",
       "      (0): ConvBnReLU3d(\n",
       "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): ConvBnReLU3d(\n",
       "        (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (resse): Sequential(\n",
       "      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Unflatten(dim=1, unflattened_size=(64, 1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (fine_3d_1): HDCResSE(\n",
       "    (hdc): ResHDCModule()\n",
       "    (resse): Sequential(\n",
       "      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Unflatten(dim=1, unflattened_size=(64, 1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (fine_3d_2): HDCResSE(\n",
       "    (hdc): ResHDCModule()\n",
       "    (resse): Sequential(\n",
       "      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Unflatten(dim=1, unflattened_size=(128, 1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (fine_3d_3): HDCResSE(\n",
       "    (hdc): ResHDCModule()\n",
       "    (resse): Sequential(\n",
       "      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Unflatten(dim=1, unflattened_size=(64, 1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (coarse_3d_3): DoubleConvResSE(\n",
       "    (conv): Sequential(\n",
       "      (0): ConvBnReLU3d(\n",
       "        (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): ConvBnReLU3d(\n",
       "        (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (resse): Sequential(\n",
       "      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Unflatten(dim=1, unflattened_size=(64, 1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (coarse_3d_4): DoubleConvResSE(\n",
       "    (conv): Sequential(\n",
       "      (0): ConvBnReLU3d(\n",
       "        (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): ConvBnReLU3d(\n",
       "        (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (resse): Sequential(\n",
       "      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Unflatten(dim=1, unflattened_size=(32, 1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (one_d_1): Sequential(\n",
       "    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (one_d_2): Sequential(\n",
       "    (0): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (one_d_3): Sequential(\n",
       "    (0): Conv3d(32, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=same)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       "  (downsample1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (downsample2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (upsample1): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (upsample2): ConvTranspose3d(32, 16, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.Model.OrganNet25D import OrganNet25D\n",
    "model_config = {\n",
    "        \"name\": \"OrganNet25D\",\n",
    "        \"padding\": \"yes\",\n",
    "        \"activations\": {\n",
    "            \"coarse_resse\": \"sigmoid\",\n",
    "            \"fine_resse\": \"sigmoid\",\n",
    "            \"2d\": \"relu\",\n",
    "            \"one_d_1\": \"relu\",\n",
    "            \"one_d_2\": \"relu\",\n",
    "            \"one_d_3\": \"softmax\"\n",
    "        },\n",
    "        \"hdc_out_channels\": [\n",
    "            64,\n",
    "            128,\n",
    "            64\n",
    "        ],\n",
    "        \"hdc_dilations\": [\n",
    "            [\n",
    "                1,\n",
    "                2,\n",
    "                7,\n",
    "                11,\n",
    "                13\n",
    "            ],\n",
    "            [\n",
    "                1,\n",
    "                2,\n",
    "                7,\n",
    "                13,\n",
    "                17\n",
    "            ],\n",
    "            [\n",
    "                5,\n",
    "                9,\n",
    "                17\n",
    "            ]\n",
    "        ]\n",
    "    }\n",
    "model_path = Path(\"trained_model\") / \"checkpoint.tar\"\n",
    "model = OrganNet25D(**model_config)\n",
    "model.load_state_dict(torch.load(model_path,map_location=torch.device(\"cpu\"))[\"model\"])\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [03:37,  5.68s/it]"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/Users/veikko/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "from src.losses import DiceCoefficient\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    iterator_wrapper = tqdm\n",
    "except ImportError:\n",
    "    iterator_wrapper = lambda x: x\n",
    "\n",
    "dsc = DiceCoefficient()\n",
    "\n",
    "averages = []\n",
    "dsc_per_channel = []\n",
    "\n",
    "for batch, batch_input in iterator_wrapper(enumerate(eval_data)):\n",
    "    inputs, labels = batch_input\n",
    "    prediction = model(inputs)\n",
    "    \n",
    "    avg, per_channel = dsc(prediction, labels, return_per_channel_dsc=True)\n",
    "    \n",
    "    averages.append(averages)\n",
    "    dsc_per_channel.append(per_channel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2591, 0.0076, 0.1128, 0.0040, 0.1266, 0.0000, 0.0433, 0.0000, 0.0000,\n",
       "        0.9618], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/veikko/Documents/GitHub/organ-segmentation/evaluate.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/veikko/Documents/GitHub/organ-segmentation/evaluate.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/veikko/Documents/GitHub/organ-segmentation/evaluate.ipynb#ch0000012?line=2'>3</a>\u001b[0m fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/veikko/Documents/GitHub/organ-segmentation/evaluate.ipynb#ch0000012?line=4'>5</a>\u001b[0m axes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mimshow(inputs[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,:,:])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/veikko/Documents/GitHub/organ-segmentation/evaluate.ipynb#ch0000012?line=5'>6</a>\u001b[0m axes[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mimshow(labels[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,:,:])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/veikko/Documents/GitHub/organ-segmentation/evaluate.ipynb#ch0000012?line=6'>7</a>\u001b[0m axes[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mimshow(prediction[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,:,:]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,10))\n",
    "\n",
    "axes[0].imshow(inputs[0,0,0,:,:])\n",
    "axes[1].imshow(labels[0,0,0,:,:])\n",
    "axes[2].imshow(prediction[0,0,0,:,:].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Chen, Z., Li, C., He, J., Ye, J., Song, D., Wang, S., ... & Qiao, Y. (2021, September). A Novel Hybrid Convolutional Neural Network for Accurate Organ Segmentation in 3D Head and Neck CT Images. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 569-578). Springer, Cham.\n",
    "[2] Wang, P., Chen, P., Yuan, Y., Liu, D., Huang, Z., Hou, X., & Cottrell, G. (2018, March). Understanding convolution for semantic segmentation. In 2018 IEEE winter conference on applications of computer vision (WACV) (pp. 1451-1460). Ieee."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e11b39e258ce4d5d8da63d84a4ce623d390dee4c95f501d4ac42e2eea86ca73b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
