{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import numpy as np # For general mathematical operations\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt # For plotting the results\n",
    "from torchinfo import summary # For model summaries\n",
    "from torch.utils.tensorboard import SummaryWriter # For writing into tensorboard\n",
    "import nrrd # For reading and manipulating nrrd files\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop focal loss\n",
    "\n",
    "Specifically solve the alpha issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2577)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.Tensor(\n",
    "[0.5, 1.0, 4.0, 1.0, 4.0, 4.0, 1.0, 1.0, 3.0, 3.0]\n",
    ")  # TODO: focal loss weights per channels from the paper\n",
    "\n",
    "\n",
    "gamma = 2.0\n",
    "dims = [2, 10, 20, 30, 30]\n",
    "weights = torch.ones(dims)\n",
    "alpha_transformed = (weights.transpose(1,-1)*alpha).transpose(1,-1).view(-1)\n",
    "\n",
    "targets = torch.rand(dims)\n",
    "inputs = (torch.rand(dims) + targets) / 2\n",
    "\n",
    "# Add error specifically to channel 0\n",
    "inputs[0,...] = torch.rand(dims[1:])\n",
    "\n",
    "orig_input_shape = inputs.shape\n",
    "# flatten label and prediction tensors\n",
    "inputs = inputs.view(-1)\n",
    "targets = targets.view(-1)\n",
    "# first compute binary cross-entropy\n",
    "\n",
    "BCE = F.binary_cross_entropy(inputs, targets, weight=alpha_transformed, reduction=\"mean\")\n",
    "\n",
    "BCE_EXP = torch.exp(-BCE)\n",
    "focal_loss = (1 - BCE_EXP) ** gamma * BCE\n",
    "\n",
    "\n",
    "focal_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then the dice loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ sizes\n",
      "tensor([0.4995, 0.9504, 0.5005, 0.5000, 0.4995, 0.5003, 0.5013, 0.5009, 0.5004,\n",
      "        0.5008])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0450),\n",
       " (tensor(0.2152),\n",
       "  tensor([0.0909, 1.0000, 0.4242, 0.0909, 0.0909, 0.0910, 0.0911, 0.0910, 0.0911,\n",
       "          0.0910])))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = [2,10, 50, 100, 50]\n",
    "def old(inputs, targets):\n",
    "    channels = inputs.size()[1]\n",
    "    inputs = inputs[:].contiguous().view(-1)\n",
    "    targets = targets[:].contiguous().view(-1)\n",
    "    intersection = (inputs * targets).sum()\n",
    "    dice = ((2.0 * intersection) / (inputs.sum() + targets.sum())) / channels\n",
    "    return dice\n",
    "\n",
    "def new(inputs, targets, return_per_channel=False):\n",
    "    # Compute the elementwise operations p * y and p + y\n",
    "    dice_top = 2 * inputs * targets + 1e-4\n",
    "    dice_bottom = (inputs + targets + 1e-4)\n",
    "    dice = dice_top / dice_bottom\n",
    "    dsc_per_channel = dice.mean(dim=(0,3,2,4))\n",
    "    dsc_avg = dsc_per_channel.mean()\n",
    "\n",
    "    if return_per_channel:\n",
    "        return dsc_avg, dsc_per_channel\n",
    "\n",
    "    return dsc_avg\n",
    "\n",
    "targets = (torch.rand(dims))\n",
    "targets[:,1] *= 10 # Big organ -> 3 times the size\n",
    "targets[:,0] *= 1 # Small organ -> Half the size\n",
    "targets = targets.round(decimals=0)\n",
    "targets[targets > 1] = 1\n",
    "\n",
    "inputs = torch.nn.Softmax(dim=1)(torch.rand_like(targets))\n",
    "\n",
    "good_ch = 1\n",
    "bad_ch = 2\n",
    "\n",
    "basic_error = 1.0\n",
    "good_error =  0.\n",
    "bad_error = 0.3\n",
    "\n",
    "diff = targets - inputs\n",
    "inputs += (1.0-basic_error)*diff # Normal error\n",
    "\n",
    "diff = targets - inputs\n",
    "inputs[:,good_ch] +=(1-good_error)*diff[:, good_ch] # Good channel\n",
    "\n",
    "diff = targets - inputs\n",
    "inputs[:, bad_ch] += (1.0-bad_error)*diff[:, bad_ch] # BAD Channel\n",
    "\n",
    "old_dsc = old(inputs, targets)\n",
    "new_dsc = new(inputs,targets, return_per_channel=True)\n",
    "\n",
    "print(\"Organ sizes\")\n",
    "print((targets == 1).sum(dim=(0,2,3,4)) / (targets.numel()/targets.shape[1]))\n",
    "\n",
    "old_dsc.round(decimals=3), new_dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0969)\n"
     ]
    }
   ],
   "source": [
    "dice_top = 2 * inputs * targets + 1e-4\n",
    "dice_bottom = (inputs + targets + 1e-4)\n",
    "dice = dice_top / dice_bottom\n",
    "dsc_per_channel = dice.mean(dim=(0,3,2,4))\n",
    "dsc_per_channel = dice.mean()\n",
    "#dsc_avg = dsc_per_channel.mean()\n",
    "\n",
    "print(dsc_per_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(230.9566), tensor(0.5849))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diceloss = 0\n",
    "dims = (18,27,27)\n",
    "targets = torch.rand(dims)\n",
    "inputs = (torch.rand(dims) + targets) / 2\n",
    "\n",
    "p = inputs\n",
    "y = targets\n",
    "diceloss += (2*(p*y)/(p+y)).sum()\n",
    "\n",
    "diceloss /= dims[1]\n",
    "\n",
    "diceloss, forward(inputs, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "class DiceCoefficient(nn.Module):\n",
    "    def __init__(self, eps=1e-4, **params):\n",
    "        self.eps = eps\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, reduce_method=\"mean\", return_per_channel_dsc=False):\n",
    "        # Compute the dice coefficient\n",
    "\n",
    "        dice_top = 2 * inputs * targets\n",
    "        dice_bottom = inputs + targets + self.eps\n",
    "        dice = dice_top / dice_bottom\n",
    "\n",
    "        dsc_per_channel = dice.sum(dim=(0, 3, 2, 4))\n",
    "\n",
    "        organ_sizes = (targets == 1).sum(dim=(0, 3, 2, 4))\n",
    "        dsc_per_channel = torch.divide(dsc_per_channel, organ_sizes + self.eps)\n",
    "\n",
    "        dsc_avg = dsc_per_channel.mean()\n",
    "\n",
    "        if return_per_channel_dsc:\n",
    "            return dsc_avg, dsc_per_channel\n",
    "\n",
    "        return dsc_avg\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-4, **params):\n",
    "        self.eps = eps\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, reduce_method=\"mean\", return_per_channel_dsc=False):\n",
    "        dice = DiceCoefficient(eps=self.eps)(\n",
    "            inputs, targets, reduce_method=reduce_method, return_per_channel_dsc=return_per_channel_dsc\n",
    "        )\n",
    "        if return_per_channel_dsc:\n",
    "            loss, per_channel = dice\n",
    "            return 1 - loss, per_channel\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses import DiceCoefficient, DiceLoss, CombinedLoss, FocalLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets\n",
      "Ch 0\n",
      "[[[[1. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "   [1. 1. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 1. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      "   [0. 1. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "   [1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]]\n",
      "\n",
      "  [[0. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [0. 1. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "   [1. 0. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "   [0. 1. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 1. 0. 1. 0. 1. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [0. 1. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "   [1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [1. 1. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 0. 1. 1. 0. 0. 0. 1. 1. 0.]]\n",
      "\n",
      "  [[0. 0. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "   [1. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "   [0. 1. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "   [0. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "   [1. 0. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "   [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 1. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
      "   [1. 0. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      "   [1. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "   [1. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [0. 0. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]]\n",
      "\n",
      "  [[1. 1. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "   [1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "   [1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "   [0. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "   [1. 0. 1. 1. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]]\n",
      "\n",
      "  [[0. 0. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "   [1. 0. 0. 0. 1. 0. 1. 1. 1. 0.]\n",
      "   [0. 0. 0. 0. 1. 1. 1. 0. 1. 0.]]\n",
      "\n",
      "  [[0. 1. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "   [0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "   [0. 1. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
      "   [1. 0. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]\n",
      "\n",
      "  [[0. 0. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
      "   [1. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 1. 0. 1. 0. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      "   [0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]]]]\n",
      "Ch 1\n",
      "[[[[1. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 1. 0. 0. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "   [0. 0. 0. 1. 0. 1. 1. 0. 1. 0.]\n",
      "   [0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "   [1. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "   [0. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "   [1. 0. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 1. 0. 0. 1. 1. 1. 0.]]\n",
      "\n",
      "  [[0. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 1. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "   [0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "   [0. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 1. 0. 1. 1. 0. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 1. 0. 1. 0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "   [1. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "   [0. 1. 1. 1. 0. 0. 0. 1. 0. 1.]\n",
      "   [0. 1. 0. 1. 0. 1. 1. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "   [1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "   [0. 1. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 1. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1. 0. 1. 1. 0. 0.]]\n",
      "\n",
      "  [[1. 1. 0. 0. 1. 0. 1. 1. 1. 0.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "   [1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "   [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]]\n",
      "\n",
      "  [[1. 0. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "   [0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
      "   [1. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "   [0. 1. 0. 1. 0. 1. 0. 1. 1. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 1. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "   [1. 0. 1. 1. 0. 0. 0. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "   [0. 1. 1. 1. 0. 1. 0. 0. 1. 0.]\n",
      "   [0. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "   [0. 1. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "   [1. 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "   [1. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
      "   [0. 1. 1. 1. 0. 1. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 1. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "   [0. 0. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "   [1. 1. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "   [1. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "   [1. 1. 0. 1. 0. 1. 0. 1. 1. 0.]]]]\n",
      "Predictions\n",
      "Ch 0\n",
      "[[[[1. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "   [1. 1. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 1. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      "   [0. 1. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "   [1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]]\n",
      "\n",
      "  [[0. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [0. 1. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "   [1. 0. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "   [0. 1. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 1. 0. 1. 0. 1. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [0. 1. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "   [1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [1. 1. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 0. 1. 1. 0. 0. 0. 1. 1. 0.]]\n",
      "\n",
      "  [[0. 0. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "   [1. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "   [0. 1. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "   [0. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "   [1. 0. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "   [1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 1. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
      "   [1. 0. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      "   [1. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "   [1. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [0. 0. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]]\n",
      "\n",
      "  [[1. 1. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "   [1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "   [1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "   [0. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "   [1. 0. 1. 1. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]]\n",
      "\n",
      "  [[0. 0. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "   [1. 0. 0. 0. 1. 0. 1. 1. 1. 0.]\n",
      "   [0. 0. 0. 0. 1. 1. 1. 0. 1. 0.]]\n",
      "\n",
      "  [[0. 1. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "   [0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "   [0. 1. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
      "   [1. 0. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]\n",
      "\n",
      "  [[0. 0. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
      "   [1. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "   [0. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 1. 0. 1. 0. 1. 0. 1.]\n",
      "   [1. 0. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      "   [0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]]]]\n",
      "Ch 1\n",
      "[[[[1. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 1. 0. 0. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "   [0. 0. 0. 1. 0. 1. 1. 0. 1. 0.]\n",
      "   [0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "   [1. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "   [0. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "   [1. 0. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 1. 0. 0. 1. 1. 1. 0.]]\n",
      "\n",
      "  [[0. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 1. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "   [0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "   [0. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 1. 0. 1. 1. 0. 1. 0. 1. 0.]\n",
      "   [1. 1. 1. 1. 0. 1. 0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "   [1. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "   [0. 1. 1. 1. 0. 0. 0. 1. 0. 1.]\n",
      "   [0. 1. 0. 1. 0. 1. 1. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "   [1. 1. 1. 0. 1. 1. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "   [0. 0. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "   [1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "   [0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "   [0. 1. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 1. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1. 0. 1. 1. 0. 0.]]\n",
      "\n",
      "  [[1. 1. 0. 0. 1. 0. 1. 1. 1. 0.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [0. 1. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "   [1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "   [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]]\n",
      "\n",
      "  [[1. 0. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "   [0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "   [0. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "   [0. 0. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
      "   [1. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [0. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "   [0. 1. 0. 1. 0. 1. 0. 1. 1. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 1. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "   [0. 1. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "   [1. 0. 1. 1. 0. 0. 0. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "   [0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "   [0. 1. 1. 1. 0. 1. 0. 0. 1. 0.]\n",
      "   [0. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "   [0. 1. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "   [1. 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "   [0. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "   [1. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
      "   [0. 1. 1. 1. 0. 1. 1. 0. 0. 0.]]\n",
      "\n",
      "  [[1. 1. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      "   [1. 1. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "   [0. 0. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "   [1. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "   [0. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "   [1. 1. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "   [1. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "   [1. 1. 0. 1. 0. 1. 0. 1. 1. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "eps = 1e-4\n",
    "dsc = DiceCoefficient(eps=eps)\n",
    "dsloss = DiceLoss(eps=eps)\n",
    "combined = CombinedLoss(alpha=[1.0], eps=eps)\n",
    "focal = FocalLoss(eps=eps)\n",
    "\n",
    "dim = (1,2,10,10,10)\n",
    "\n",
    "targets = torch.rand(dim).round(decimals=0)\n",
    "inputs = deepcopy(targets)\n",
    "\n",
    "print(\"Targets\")\n",
    "print(\"Ch 0\")\n",
    "print(targets[:,0].numpy())\n",
    "print(\"Ch 1\")\n",
    "print(targets[:,1].numpy())\n",
    "\n",
    "\n",
    "print(\"Predictions\")\n",
    "print(\"Ch 0\")\n",
    "print(inputs[:,0].numpy())\n",
    "print(\"Ch 1\")\n",
    "print(inputs[:,1].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dice coefficient + mean\n",
      "4939327.0\n",
      "[4877368.  5001286.5]\n",
      "Dice loss\n",
      "5.018711e-05\n",
      "[0.9999498  0.99994975]\n",
      "Focal\n",
      "0.31057513\n",
      "Combined\n",
      "0.7082253\n",
      "[0.5925514 0.6121482]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "print(\"Dice coefficient + mean\")\n",
    "coeff, per_ch = dsc(inputs, inputs, return_per_channel_dsc=True)\n",
    "print(coeff.numpy())\n",
    "print(per_ch.numpy())\n",
    "\n",
    "print(\"Dice loss\")\n",
    "loss, per_ch = dsloss(targets, targets, return_per_channel_dsc=True)\n",
    "print(loss.numpy())\n",
    "print(per_ch.numpy())\n",
    "\n",
    "print(\"Focal\")\n",
    "focal_loss = focal(inputs, targets, alpha=torch.Tensor([1.0]))\n",
    "print(focal_loss.numpy())\n",
    "\n",
    "\n",
    "print(\"Combined\")\n",
    "combined_loss, per_ch = combined(inputs, targets,return_per_channel_dsc=True)\n",
    "print(combined_loss.numpy())\n",
    "print(per_ch.numpy())\n",
    "\n",
    "inputs = deepcopy(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(520) tensor(520) tensor(1.)\n",
      "tensor(518) tensor(518) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "n_correct_ch_zero = ((targets[0,0].view(-1) == 1) & (targets[0,0].view(-1) == inputs[0,0].view(-1))).sum()\n",
    "n_correct_ch_one = ((targets[0,1].view(-1) == 1) & (targets[0,1].view(-1) == inputs[0,1].view(-1))).sum()\n",
    "\n",
    "print(n_correct_ch_zero, (targets[0,0].view(-1) == 1).sum(),n_correct_ch_zero / (targets[0,0].view(-1) == 1).sum())\n",
    "print(n_correct_ch_one,(targets[0,1].view(-1) == 1).sum(), n_correct_ch_one / (targets[0,1].view(-1) == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dice coefficient + mean\n",
      "0.20762101\n",
      "[0.2078154  0.20742662]\n",
      "Dice loss\n",
      "0.792379\n",
      "[0.2078154  0.20742662]\n",
      "Combined\n",
      "1.7922175\n",
      "[0.2078154  0.20742662]\n",
      "Focal\n",
      "0.9998385\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = deepcopy(targets)\n",
    "\n",
    "#inputs[0,0,0,:,:] = 1 - targets[0,0,0,:,:]\n",
    "#inputs[0,1,0,:,:] = 1 - targets[0,1,0,:,:]\n",
    "\n",
    "inputs = torch.rand_like(targets) * 0.25\n",
    "# inputs[0,0,:,:,:] = targets[0,0,:,:,:]  * 0.1\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Dice coefficient + mean\")\n",
    "coeff, per_ch = dsc(inputs, targets, return_per_channel_dsc=True)\n",
    "print(coeff.numpy())\n",
    "print(per_ch.numpy())\n",
    "\n",
    "print(\"Dice loss\")\n",
    "loss, per_ch = DiceLoss(eps=eps)(inputs, targets, return_per_channel_dsc=True)\n",
    "print(loss.numpy())\n",
    "print(per_ch.numpy())\n",
    "alpha_ch0 = 1.0\n",
    "alpha_ch1 = 1.0\n",
    "print(\"Combined\")\n",
    "combined = CombinedLoss(alpha=[alpha_ch0, alpha_ch1])\n",
    "combined_loss, per_ch = combined(inputs, targets, return_per_channel_dsc=True)\n",
    "print(combined_loss.numpy())\n",
    "print(per_ch.numpy())\n",
    "\n",
    "\n",
    "print(\"Focal\")\n",
    "focal_loss = focal(inputs, targets, alpha=combined.get_alpha(inputs))\n",
    "print(focal_loss.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6122), tensor([0.6047, 0.6196]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = deepcopy(targets)\n",
    "\n",
    "#inputs[0,0,0,:,:] = 1 - targets[0,0,0,:,:]\n",
    "#inputs[0,1,0,:,:] = 1 - targets[0,1,0,:,:]\n",
    "\n",
    "inputs = torch.rand_like(targets)\n",
    "#inputs[0,1,:,:,:] = targets[0,1,:,:,:]\n",
    "\n",
    "dice_top = 2 * inputs * targets\n",
    "dice_bottom = inputs + targets + 1e-4\n",
    "dice = dice_top / dice_bottom\n",
    "\n",
    "dsc_per_channel = dice.sum(dim=(0, 3, 2, 4))\n",
    "\n",
    "organ_sizes = (targets == 1).sum(dim=(0, 3, 2, 4))\n",
    "dsc_per_channel = torch.divide(dsc_per_channel, organ_sizes + 1e-4)\n",
    "\n",
    "dsc_avg = dsc_per_channel.mean()\n",
    "\n",
    "dsc_avg, dsc_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6258, 0.6093]), tensor(0.6176))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_top = 2 * inputs * targets\n",
    "dice_bottom = inputs + targets + 1e-4\n",
    "dice = dice_top / dice_bottom\n",
    "\n",
    "dsc_per_channel = dice.sum(dim=(0, 3, 2, 4))\n",
    "\n",
    "organ_sizes = (targets == 1).sum(dim=(0, 3, 2, 4))\n",
    "dsc_per_channel = torch.divide(dsc_per_channel, organ_sizes +  1e-4)\n",
    "\n",
    "dsc_avg = dsc_per_channel.mean()\n",
    "\n",
    "dsc_per_channel, dsc_avg"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e11b39e258ce4d5d8da63d84a4ce623d390dee4c95f501d4ac42e2eea86ca73b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
