{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import numpy as np # For general mathematical operations\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt # For plotting the results\n",
    "from torchinfo import summary # For model summaries\n",
    "from torch.utils.tensorboard import SummaryWriter # For writing into tensorboard\n",
    "import nrrd # For reading and manipulating nrrd files\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop focal loss\n",
    "\n",
    "Specifically solve the alpha issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2587)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.Tensor(\n",
    "[0.5, 1.0, 4.0, 1.0, 4.0, 4.0, 1.0, 1.0, 3.0, 3.0]\n",
    ")  # TODO: focal loss weights per channels from the paper\n",
    "\n",
    "\n",
    "gamma = 2.0\n",
    "dims = [2, 10, 20, 30, 30]\n",
    "weights = torch.ones(dims)\n",
    "alpha_transformed = (weights.transpose(1,-1)*alpha).transpose(1,-1).view(-1)\n",
    "\n",
    "targets = torch.rand(dims)\n",
    "inputs = (torch.rand(dims) + targets) / 2\n",
    "\n",
    "# Add error specifically to channel 0\n",
    "inputs[0,...] = torch.rand(dims[1:])\n",
    "\n",
    "orig_input_shape = inputs.shape\n",
    "# flatten label and prediction tensors\n",
    "inputs = inputs.view(-1)\n",
    "targets = targets.view(-1)\n",
    "# first compute binary cross-entropy\n",
    "\n",
    "BCE = F.binary_cross_entropy(inputs, targets, weight=alpha_transformed, reduction=\"mean\")\n",
    "\n",
    "BCE_EXP = torch.exp(-BCE)\n",
    "focal_loss = (1 - BCE_EXP) ** gamma * BCE\n",
    "\n",
    "\n",
    "focal_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then the dice loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ sizes\n",
      "tensor([0.5003, 0.9503, 0.5008, 0.4999, 0.4997, 0.4994, 0.5001, 0.5014, 0.4985,\n",
      "        0.4989])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0450),\n",
       " (tensor(0.2151),\n",
       "  tensor([0.0910, 1.0000, 0.4244, 0.0910, 0.0909, 0.0908, 0.0909, 0.0911, 0.0907,\n",
       "          0.0907])))"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = [2,10, 50, 100, 50]\n",
    "def old(inputs, targets):\n",
    "    channels = inputs.size()[1]\n",
    "    inputs = inputs[:].contiguous().view(-1)\n",
    "    targets = targets[:].contiguous().view(-1)\n",
    "    intersection = (inputs * targets).sum()\n",
    "    dice = ((2.0 * intersection) / (inputs.sum() + targets.sum())) / channels\n",
    "    return dice\n",
    "\n",
    "def new(inputs, targets, return_per_channel=False):\n",
    "    # Compute the elementwise operations p * y and p + y\n",
    "    dice_top = 2 * inputs * targets + 1e-4\n",
    "    dice_bottom = (inputs + targets + 1e-4)\n",
    "    dice = dice_top / dice_bottom\n",
    "    dsc_per_channel = dice.mean(dim=(0,3,2,4))\n",
    "    dsc_avg = dsc_per_channel.mean()\n",
    "\n",
    "    if return_per_channel:\n",
    "        return dsc_avg, dsc_per_channel\n",
    "\n",
    "    return dsc_avg\n",
    "\n",
    "targets = (torch.rand(dims))\n",
    "targets[:,1] *= 10 # Big organ -> 3 times the size\n",
    "targets[:,0] *= 1 # Small organ -> Half the size\n",
    "targets = targets.round(decimals=0)\n",
    "targets[targets > 1] = 1\n",
    "\n",
    "inputs = torch.nn.Softmax(dim=1)(torch.rand_like(targets))\n",
    "\n",
    "good_ch = 1\n",
    "bad_ch = 2\n",
    "\n",
    "basic_error = 1.0\n",
    "good_error =  0.\n",
    "bad_error = 0.3\n",
    "\n",
    "diff = targets - inputs\n",
    "inputs += (1.0-basic_error)*diff # Normal error\n",
    "\n",
    "diff = targets - inputs\n",
    "inputs[:,good_ch] +=(1-good_error)*diff[:, good_ch] # Good channel\n",
    "\n",
    "diff = targets - inputs\n",
    "inputs[:, bad_ch] += (1.0-bad_error)*diff[:, bad_ch] # BAD Channel\n",
    "\n",
    "old_dsc = old(inputs, targets)\n",
    "new_dsc = new(inputs,targets, return_per_channel=True)\n",
    "\n",
    "print(\"Organ sizes\")\n",
    "print((targets == 1).sum(dim=(0,2,3,4)) / (targets.numel()/targets.shape[1]))\n",
    "\n",
    "old_dsc.round(decimals=3), new_dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0969)\n"
     ]
    }
   ],
   "source": [
    "dice_top = 2 * inputs * targets + 1e-4\n",
    "dice_bottom = (inputs + targets + 1e-4)\n",
    "dice = dice_top / dice_bottom\n",
    "dsc_per_channel = dice.mean(dim=(0,3,2,4))\n",
    "dsc_per_channel = dice.mean()\n",
    "#dsc_avg = dsc_per_channel.mean()\n",
    "\n",
    "print(dsc_per_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(230.9566), tensor(0.5849))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diceloss = 0\n",
    "dims = (18,27,27)\n",
    "targets = torch.rand(dims)\n",
    "inputs = (torch.rand(dims) + targets) / 2\n",
    "\n",
    "p = inputs\n",
    "y = targets\n",
    "diceloss += (2*(p*y)/(p+y)).sum()\n",
    "\n",
    "diceloss /= dims[1]\n",
    "\n",
    "diceloss, forward(inputs, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "tensor([[-1., -1.,  0.],\n",
      "        [ 1., -0.,  0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.,  2.,  0.],\n",
       "        [-0., -2.,  2.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.randn(2, 3).round(decimals=0)\n",
    "inputs = torch.Tensor([2])\n",
    "\n",
    "\n",
    "print(inputs)\n",
    "print(targets)\n",
    "torch.cross(targets, torch.Tensor([2]), dim=-1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e11b39e258ce4d5d8da63d84a4ce623d390dee4c95f501d4ac42e2eea86ca73b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
