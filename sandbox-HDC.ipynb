{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDC Module development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.ones((1,5,5))\n",
    "kern = torch.ones([1, 1, 3, 3])# * torch.Tensor([1,2,3])\n",
    "kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 7]), torch.Size([1, 4, 4]), torch.Size([1, 5, 5]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2,dilation=1, padding=(1,1))\n",
    "c2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, dilation=1, padding=\"valid\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "   c1.weight = nn.Parameter(kern)\n",
    "   c2.weight = nn.Parameter(kern)\n",
    "   c1.bias = nn.Parameter(torch.Tensor([0]))\n",
    "   c2.bias = nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "input = torch.rand((1,7,7)).round(decimals=0)#(torch.ones((1,10,10)) * 1)\n",
    "\n",
    "out1 = c1(input)\n",
    "out2 = c2(input)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "input.shape, out1.shape, out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 1., 1., 1.],\n",
      "         [1., 0., 1., 0., 1., 0., 1.],\n",
      "         [1., 0., 0., 0., 1., 1., 0.],\n",
      "         [1., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 0., 0., 1.],\n",
      "         [0., 1., 0., 1., 1., 0., 1.]]])\n",
      "\n",
      "tensor([[[1., 1., 3., 3., 3., 2., 3.],\n",
      "         [3., 1., 5., 2., 5., 2., 4.],\n",
      "         [1., 2., 4., 5., 5., 4., 5.],\n",
      "         [5., 3., 7., 4., 7., 3., 5.],\n",
      "         [1., 3., 4., 5., 5., 4., 5.],\n",
      "         [3., 3., 4., 4., 4., 3., 3.],\n",
      "         [0., 3., 2., 4., 4., 3., 4.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "tensor([[[4., 5., 5.],\n",
      "         [7., 4., 7.],\n",
      "         [4., 5., 5.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(input)\n",
    "print()\n",
    "print(out1)\n",
    "print()\n",
    "print(out2)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.rand((2, 10, 48, 256, 256))\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "soft = nn.Softmax(dim=1)\n",
    "\n",
    "o = sig(i)\n",
    "o2 = soft(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1013, 0.1014, 0.1015,  ..., 0.1197, 0.1199, 0.1201])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2.max(dim=1).values.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Model.OrganNet25D import OrganNet25D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising organNet with (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "model = OrganNet25D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/veikko/Documents/GitHub/organ-segmentation/sandbox-HDC.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/veikko/Documents/GitHub/organ-segmentation/sandbox-HDC.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/veikko/Documents/GitHub/organ-segmentation/sandbox-HDC.ipynb#ch0000009?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(layer\u001b[39m.\u001b[39;49mgrad)\n",
      "File \u001b[0;32m~/Documents/GitHub/organ-segmentation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/veikko/Documents/GitHub/organ-segmentation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1182'>1183</a>\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   <a href='file:///Users/veikko/Documents/GitHub/organ-segmentation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1183'>1184</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> <a href='file:///Users/veikko/Documents/GitHub/organ-segmentation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1184'>1185</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///Users/veikko/Documents/GitHub/organ-segmentation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1185'>1186</a>\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "for layer in model.children():\n",
    "    print(layer.grad)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e11b39e258ce4d5d8da63d84a4ce623d390dee4c95f501d4ac42e2eea86ca73b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
